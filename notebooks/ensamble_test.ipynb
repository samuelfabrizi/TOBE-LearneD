{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2956869f",
   "metadata": {},
   "source": [
    "# Ensemble methods to compute participants' contribution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2156204",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c20d276",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-21 16:37:00.027516: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-12-21 16:37:00.027586: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "from decentralized_smart_grid_ml.federated_learning.federated_aggregator import weighted_average_aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ef373e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tensorflow.keras.experimental import LinearModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fedb5ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69de9065",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_path1 = \"../data_sample/simple_ml_task/participants/participant_0/simple_ml_task_0.csv\"\n",
    "train_set_df1 = pd.read_csv(train_set_path1)\n",
    "x_train1, y_train1 = train_set_df1[[\"x1\", \"x2\"]].values[:10], train_set_df1[\"y\"].values[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96f9fa33",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_path2 = \"../data_sample/simple_ml_task/participants/participant_1/simple_ml_task_1.csv\"\n",
    "train_set_df2 = pd.read_csv(train_set_path2)\n",
    "x_train2, y_train2 = train_set_df2[[\"x1\", \"x2\"]].values, train_set_df2[\"y\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "811636e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-21 16:38:18.153554: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2021-12-21 16:38:18.153582: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2021-12-21 16:38:18.153608: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (Lenovo-ideapad): /proc/driver/nvidia/version does not exist\n",
      "2021-12-21 16:38:18.153860: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model1 = LinearModel(activation=\"sigmoid\")\n",
    "model1.compile(optimizer=\"sgd\", loss=\"mse\", metrics=\"accuracy\")\n",
    "\n",
    "model2 = LinearModel(activation=\"sigmoid\")\n",
    "model2.compile(optimizer=\"sgd\", loss=\"mse\", metrics=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d5f1270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1/1 [==============================] - 0s 248ms/step - loss: 0.2500 - accuracy: 0.3000\n",
      "Epoch 2/3\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2293 - accuracy: 0.7000\n",
      "Epoch 3/3\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2161 - accuracy: 0.7000\n",
      "Epoch 1/3\n",
      "107/107 [==============================] - 0s 796us/step - loss: 0.0881 - accuracy: 0.9874\n",
      "Epoch 2/3\n",
      "107/107 [==============================] - 0s 840us/step - loss: 0.0255 - accuracy: 0.9997\n",
      "Epoch 3/3\n",
      "107/107 [==============================] - 0s 888us/step - loss: 0.0157 - accuracy: 0.9997\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2b444f0130>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(x_train1, y_train1, epochs=3)\n",
    "model2.fit(x_train2, y_train2, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b85a400",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [model1, model2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "099959d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_set_path = \"../data_sample/simple_ml_task/validator/simple_ml_task_validation.csv\"\n",
    "val_set_df = pd.read_csv(validation_set_path)\n",
    "x_val, y_val = val_set_df[[\"x1\", \"x2\"]].values, val_set_df[\"y\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "54ed459e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_path = \"../data_sample/simple_ml_task/validator/simple_ml_task_test.csv\"\n",
    "test_set_df = pd.read_csv(test_set_path)\n",
    "x_test, y_test = test_set_df[[\"x1\", \"x2\"]].values, test_set_df[\"y\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "150cb7ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 213ms/step - loss: 0.2500 - accuracy: 0.3000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2b4433c5b0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_model = LinearModel(activation=\"sigmoid\")\n",
    "global_model.compile(optimizer=\"sgd\", loss=\"mse\", metrics=\"accuracy\")\n",
    "# here the fit function is called because it needs the build. The trained model will NOT be used becuase\n",
    "# we will override its weights with the new ones\n",
    "global_model.fit(x_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6723db83",
   "metadata": {},
   "outputs": [],
   "source": [
    "participants_weights = []\n",
    "for model in models:\n",
    "    participants_weights.append(model.get_weights())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23107f12",
   "metadata": {},
   "source": [
    "# Simple average of local models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79dc4757",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_weights = weighted_average_aggregation(participants_weights, [0.5, 0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8eef822",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_model.set_weights(average_weights)\n",
    "simple_average_evaluation = global_model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03c6393",
   "metadata": {},
   "source": [
    "# Ensamble method based on local models' output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5d0e8f",
   "metadata": {},
   "source": [
    "In this approach we apply the softmax function to the output computed by each local models so that we can weight the contribution of each local model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfaa9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import softmax as sc_softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa196b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "score1 = model1.evaluate(x_test, y_test)[1]\n",
    "score2 = model2.evaluate(x_test, y_test)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b139dd17",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = [score1, score2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde2a7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = sc_softmax(scores)\n",
    "print(alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c0ff99",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensamble_general_weights = weighted_average_aggregation(participants_weights, alpha)\n",
    "global_model.set_weights(ensamble_general_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e6215b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensamble_general_evaluation = global_model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1666983b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a3473fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load models from file\n",
    "def load_all_models(participants_weights):\n",
    "    all_models = []\n",
    "    for participant_weights in participants_weights:\n",
    "        model = LinearModel(activation=\"sigmoid\")\n",
    "        model.compile(optimizer=\"sgd\", loss=\"mse\", metrics=\"accuracy\")\n",
    "        model.fit(x_train1, y_train1)\n",
    "        model.set_weights(participant_weights)\n",
    "        all_models.append(model)\n",
    "    return all_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1fe09a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import dstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "edff2834",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stacked_dataset(members, inputX):\n",
    "    stackX = None\n",
    "    for model in members:\n",
    "        # make prediction\n",
    "        yhat = model.predict(inputX, verbose=0)\n",
    "        # stack predictions into [rows, members, probabilities]\n",
    "        if stackX is None:\n",
    "            stackX = yhat\n",
    "        else:\n",
    "            stackX = dstack((stackX, yhat))\n",
    "    # flatten predictions to [rows, members x probabilities]\n",
    "    stackX = stackX.reshape((stackX.shape[0], stackX.shape[1]*stackX.shape[2]))\n",
    "    return stackX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8a94cb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_stacked_model(members, inputX, inputy):\n",
    "    # create dataset using ensemble\n",
    "    stackedX = stacked_dataset(members, inputX)\n",
    "    # fit standalone model\n",
    "    model = LogisticRegression()\n",
    "    model.fit(stackedX, inputy)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0767f981",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a prediction with the stacked model\n",
    "def stacked_prediction(members, model, inputX):\n",
    "    # create dataset using ensemble\n",
    "    stackedX = stacked_dataset(members, inputX)\n",
    "    # make a prediction\n",
    "    yhat = model.predict(stackedX)\n",
    "    return yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9b79e8ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 212ms/step - loss: 0.2500 - accuracy: 0.3000\n",
      "1/1 [==============================] - 0s 208ms/step - loss: 0.2500 - accuracy: 0.3000\n"
     ]
    }
   ],
   "source": [
    "models = load_all_models(participants_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f454322a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.490\n",
      "Model Accuracy: 1.000\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    _, acc = model.evaluate(x_test, y_test, verbose=0)\n",
    "    print('Model Accuracy: %.3f' % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c89b1a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2ad6fb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "55038540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacked Test Accuracy: 1.000\n"
     ]
    }
   ],
   "source": [
    "model = fit_stacked_model(models, x_test, y_test)\n",
    "yhat = stacked_prediction(models, model, x_test)\n",
    "acc = accuracy_score(y_test, yhat)\n",
    "print('Stacked Test Accuracy: %.3f' % acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec2dc02",
   "metadata": {},
   "source": [
    "# IMPORTANT:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca8bccf",
   "metadata": {},
   "source": [
    "Read here https://machinelearningmastery.com/weighted-average-ensemble-for-deep-learning-neural-networks/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d55ef3",
   "metadata": {},
   "source": [
    "# Comparison of aggregation methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e8c258",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Simple average evaluation: %s\" % simple_average_evaluation)\n",
    "print(\"Ensamble general evaluation: %s\" % ensamble_general_evaluation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
